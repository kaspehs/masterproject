data:
  file: data.npz
  steadystate: false
  steadystate_time_threshold: 10.0
  reduce_time: true
  reduction_factor: 100
  middle_time_plot: [15, 17]
  use_generated_train_series: false
  train_series_dir: Data_Gen/generated_series
  context_len: 20

model:
  rho: 1000.0
  D: 0.1
  structural_mass: 16.79
  Ca: 1.0
  k: 1218.0
  U: 0.65
  damping_c: 1e-4
  max_damping_ratio: 0.2
  include_physical_drag: false
  learn_hamiltonian: false
  discover_damping: false
  use_pirate_force: false
  pirate_force_kwargs: {}
  use_fourier_features: false
  fourier_features: 16
  fourier_sigma: 1.0
  use_feature_engineering: false

smoothing:
  use_savgol_smoothing: true
  window_length: 7
  polyorder: 3

architecture:
  force_net_type: residual
  force_context_mode: cnn  # options: none, flatten, cnn
  context_cnn_channels: 64
  cnn_kwargs:
    channels: [2, 2]
    kernel_sizes: [5, 5]
    dilations: [1, 1]
    paddings: 0  # if null, computed as dilation*(kernel-1)/2
    strides: [2, 2]
    pool: none  # global, avg, max, none
    pool_kernel: 2
    pool_stride: 2
  append_current_state: true
  residual_kwargs:
    hidden: 128
    layers: 2
    activation: gelu
  mlp_kwargs:
    hidden: 128
    layers: 2
    activation: gelu
  pirate_force_kwargs:
    fourier_features: 96
    sigma: 0.5
    use_rwf: true
    activation: tanh

training:
  batch_size: 256
  force_reg: 0.1
  max_grad_norm: 10000.0
  lr: 0.0003
  optimizer: adam
  weight_decay: 1e-5
  epochs: 5000
  rollout_every_epoch: 50
  use_lr_scheduler: true
  scheduler:
    max_lr: 0.0001
    decay_rate: 0.99
    warmup_steps: 250
    decay_steps: 4750
    min_lr: 0.00001
    scheduler_type: cosine
  use_gradnorm: false
  gradnorm_alpha: 0.9
  gradnorm_min_weight: 0.2
  gradnorm_max_weight: 5.0

logging:
  run_dir_root: HNNruns

#For running all config files
#ls HNNrunconfigs/*.yml | xargs -P 2 -I{} python3 HNN.py --config {}
